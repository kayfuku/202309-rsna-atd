{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Import ##"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-07T10:39:09.937202Z","iopub.status.busy":"2023-10-07T10:39:09.936969Z","iopub.status.idle":"2023-10-07T10:39:09.946879Z","shell.execute_reply":"2023-10-07T10:39:09.946033Z","shell.execute_reply.started":"2023-10-07T10:39:09.937181Z"},"trusted":true},"outputs":[],"source":["###\n","is_on_kaggle = True\n","# is_on_kaggle = False\n","###\n","is_debugging = True\n","# is_debugging = False"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-07T10:39:09.948871Z","iopub.status.busy":"2023-10-07T10:39:09.948568Z","iopub.status.idle":"2023-10-07T10:39:25.732019Z","shell.execute_reply":"2023-10-07T10:39:25.731086Z","shell.execute_reply.started":"2023-10-07T10:39:09.948845Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/opt/conda/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n","  warnings.warn(_BETA_TRANSFORMS_WARNING)\n","/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n","  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"]}],"source":["# import packages\n","import os\n","import sys\n","import multiprocessing\n","from pathlib import Path\n","import random\n","from collections import defaultdict\n","from glob import glob\n","import pickle\n","from joblib import Parallel, delayed\n","import gc\n","from tqdm.notebook import tqdm\n","from tabulate import tabulate\n","import yaml\n","import datetime\n","from logging import getLogger\n","import wandb\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold, GroupKFold, StratifiedGroupKFold\n","from sklearn.metrics import accuracy_score, roc_auc_score\n","\n","import cv2\n","import pydicom\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.optim import Adam, AdamW\n","from torchvision import models\n","import torchvision.transforms.v2 as t\n","from torchvision.transforms.v2 import (Resize, Compose, RandomHorizontalFlip, \n","                                       ColorJitter, RandomAffine, RandomErasing, ToTensor)\n","import pytorch_lightning as pl\n","from pytorch_lightning import seed_everything\n","from pytorch_lightning import Trainer\n","from pytorch_lightning.loggers import WandbLogger\n","import timm\n","import albumentations as A\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Constants ##"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-07T10:39:39.803438Z","iopub.status.busy":"2023-10-07T10:39:39.803014Z","iopub.status.idle":"2023-10-07T10:39:39.813068Z","shell.execute_reply":"2023-10-07T10:39:39.811960Z","shell.execute_reply.started":"2023-10-07T10:39:39.803405Z"},"trusted":true},"outputs":[],"source":["# config file\n","cfg = {\n","    'general': {\n","        'project_name': '202309-rsna-atd',\n","        'base_path': '../../data', \n","        'exp_name': 'exp008',\n","        'seed': 42,\n","        'use_wandb': True,\n","    },\n","    'data': {\n","        'n_folds': 5,\n","        'fold_i': [0], \n","        'batch_size': 16,\n","        'batch_size_inference': 'not used',  # 16,\n","        'kls_slice_start': 0.6, \n","        'b_e_slice_start': 'not used',  # 0.0\n","        'kls_stride': 4, \n","        'b_e_stride': 'not used',  # 16, \n","        'calc_cv_score': False, \n","        'apply_aug': True,\n","    }, \n","    'model': {\n","        'model_type': 'kls',  # kls, b_e\n","        'model_name': 'maxvit_tiny_tf_384.in1k',\n","        'pretrained': True, \n","        'in_chans': 1, \n","        'num_classes': 0, # to use as backbone\n","        'global_pool': 'max',\n","        'drop_rate': 0.5, \n","        'drop_path_rate': 0.2, \n","        'hidden_dim': 128,\n","        'p_dropout': 0.3,\n","        'lr': 1.0e-4, \n","    },\n","    'pl_params': {\n","        'accelerator': 'auto',\n","        'max_epochs': 2, \n","        'precision': 16, # 16 or 32\n","        'enable_progress_bar': True, \n","        'limit_train_batches': 1.0, \n","        'limit_val_batches': 1.0, \n","    }\n","}\n","\n","if is_debugging:\n","    cfg['general']['use_wandb'] = False\n","    cfg['pl_params']['limit_train_batches'] = 0.01\n","    cfg['pl_params']['limit_val_batches'] = 0.01\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-07T10:39:42.220805Z","iopub.status.busy":"2023-10-07T10:39:42.220456Z","iopub.status.idle":"2023-10-07T10:39:42.228687Z","shell.execute_reply":"2023-10-07T10:39:42.227800Z","shell.execute_reply.started":"2023-10-07T10:39:42.220778Z"},"trusted":true},"outputs":[],"source":["# misc functions\n","torch.cuda.empty_cache()\n","# multiprocessing.set_start_method('spawn', force=True)\n","seed_everything(cfg['general']['seed'], workers=True)\n","num_workers = os.cpu_count()\n","gpu_count = torch.cuda.device_count()\n","print('num_workers:', num_workers)\n","print('gpu_count:', gpu_count)\n","\n","def random_seed(seed=42):\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    torch.cuda.manual_seed(seed)    \n","\n","def start_wandb():\n","    wandb.init(\n","        project=cfg['general'][\"project_name\"],\n","        name=cfg['general']['exp_name'],\n","        config=cfg,\n","    )\n","    wandb_logger = WandbLogger(\n","        project=cfg['general']['project_name'],\n","        name=cfg['general']['exp_name'],\n","        config=cfg,\n","    )\n","    return wandb_logger\n","\n","\n","random_seed(cfg['general']['seed'])\n","logger = start_wandb() if cfg['general']['use_wandb'] else None\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Paths ##"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-07T10:40:09.553299Z","iopub.status.busy":"2023-10-07T10:40:09.552644Z","iopub.status.idle":"2023-10-07T10:40:09.559540Z","shell.execute_reply":"2023-10-07T10:40:09.558385Z","shell.execute_reply.started":"2023-10-07T10:40:09.553271Z"},"trusted":true},"outputs":[],"source":["if is_on_kaggle:\n","    BASE_PATH = '/kaggle/input'\n","else:\n","    BASE_PATH = '.'\n","\n","TRAIN_IMG_PATHS = [\n","    f'{BASE_PATH}/rsna-abdominal-trauma-detection-png-pt1', \n","    f'{BASE_PATH}/rsna-abdominal-trauma-detection-png-pt2',\n","    f'{BASE_PATH}/rsna-2023-abdominal-trauma-detection-pngs-3-8',\n","    f'{BASE_PATH}/rsna-abdominal-trauma-detection-png-pt4',\n","    f'{BASE_PATH}/rsna-abdominal-trauma-detection-png-pt5',\n","    f'{BASE_PATH}/rsna-abdominal-trauma-detection-png-pt6',\n","    f'{BASE_PATH}/rsna-abdominal-trauma-detection-pngs-pt7',\n","    f'{BASE_PATH}/rsna-2023-abdominal-trauma-detection-pngs-18',\n","]\n","TRAIN_DF_PATH = f'{BASE_PATH}/rsna-2023-abdominal-trauma-detection/train.csv'\n","B_E_POS_PATH = f'{BASE_PATH}/b-e-data/b_e_pos.csv'\n","B_E_NEG_PATH = f'{BASE_PATH}/b-e-data/sample_b_e_neg.csv'\n","\n","# make directory to save models\n","if not os.path.exists('models'):\n","    os.mkdir('models')\n","if is_on_kaggle:\n","    MODEL_PATH = f\"./models/{cfg['model']['model_name']}_{cfg['general']['exp_name']}_{cfg['model']['model_type']}\"\n","else:\n","    MODEL_PATH = f\"../models/{cfg['model']['model_name']}_{cfg['general']['exp_name']}_{cfg['model']['model_type']}\"\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Preparing data ##"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-01T15:36:15.983440Z","iopub.status.busy":"2023-10-01T15:36:15.982817Z","iopub.status.idle":"2023-10-01T15:36:15.997890Z","shell.execute_reply":"2023-10-01T15:36:15.997053Z","shell.execute_reply.started":"2023-10-01T15:36:15.983411Z"},"trusted":true},"outputs":[],"source":["class AbdominalKLSData(Dataset):\n","\n","    def __init__(self, cfg, train_df, train_img_dirs, slice_start, stride=10, apply_aug=True, num_fold=5):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.slice_start = slice_start\n","        self.train_df = train_df\n","        self.train_img_paths = self._fetch_and_sample_train_images(train_img_dirs, stride=stride)\n","        self.augmentation = apply_aug\n","\n","        self.gkf = GroupKFold(n_splits=num_fold)\n","        groups = np.array([os.path.basename(img_path).split('_')[0] for img_path in self.train_img_paths])\n","        self.fold_data = list(self.gkf.split(self.train_img_paths, groups=groups))\n","\n","        self.normalize = Compose([\n","            # Resize((256, 256), antialias=True),\n","            # RandomHorizontalFlip(),  # Randomly flip images left-right\n","            # ColorJitter(brightness=0.2),  # Randomly adjust brightness\n","            # ColorJitter(contrast=0.2),  # Randomly adjust contrast\n","            # RandomAffine(degrees=0, shear=10),  # Apply shear transformation\n","            # RandomAffine(degrees=0, scale=(0.8, 1.2)),  # Apply zoom transformation\n","            # RandomErasing(p=0.2, scale=(0.02, 0.2)),  # Coarse dropout\n","            ToTensor(),\n","        ])\n","\n","        # augmentation\n","        # flip\n","        self.aug_h_flip = A.HorizontalFlip(p=0.5)\n","        self.aug_v_flip = A.VerticalFlip(p=0.5)\n","        # elastic and grid\n","        self.aug_distortion = A.GridDistortion(p=0.5)\n","        self.aug_elastic = A.ElasticTransform(p=0.5)\n","        # affine\n","        self.aug_affine = A.Affine(\n","            scale=(0.8, 1.2),\n","            translate_percent=(0.0, 0.2),\n","            rotate=(-45, 45),\n","            shear=(-15, 15),\n","            p=0.5)\n","        # self.aug_affine = A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.8)\n","        # clahe\n","        self.aug_clahe = A.CLAHE(p=0.5)\n","        # bright\n","        self.aug_bright = A.OneOf([\n","            A.RandomGamma(gamma_limit=(50, 150), p=0.5),\n","            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.5)\n","        ], p=0.5)\n","        # cutout\n","        self.aug_cutout = A.CoarseDropout(max_height=8, max_width=8, p=0.5)\n","        # randomcrop\n","        self.aug_randomcrop = A.RandomResizedCrop(\n","            height=256,\n","            width=256,\n","            scale=(0.8, 1.0),\n","            ratio=(3/4, 4/3),\n","            p=0.5)\n","\n","    def __len__(self):\n","        return len(self.train_img_paths)\n","\n","    def __getitem__(self, idx):\n","        sample_img_path = self.train_img_paths[idx]\n","        patient_id = int(os.path.basename(sample_img_path).split('_')[0])\n","\n","        # preprocess image\n","        img = self._process_img(sample_img_path)\n","        # img.shape: (256, 256)\n","\n","        # augmentation\n","        if self.augmentation:\n","            img = self.aug_h_flip(image=img)[\"image\"]\n","            img = self.aug_v_flip(image=img)[\"image\"]\n","            img = self.aug_distortion(image=img)[\"image\"]\n","            img = self.aug_clahe(image=img)[\"image\"]\n","            img = self.aug_affine(image=img)[\"image\"]\n","            img = self.aug_bright(image=img)[\"image\"]\n","            img = self.aug_cutout(image=img)[\"image\"]\n","            img = self.aug_randomcrop(image=img)[\"image\"]\n","\n","        img = img.astype('float32') / 255\n","        # img.shape: (256, 256)\n","\n","        img = torch.tensor(img, dtype=torch.float).unsqueeze(dim=0)\n","        # img.shape: (1, 256, 256)\n","        if self.cfg['model']['model_name'] == 'maxvit_tiny_tf_384.in1k':\n","            img = Compose([Resize((384, 384), antialias=True)])(img)\n","        img = self.normalize(img)\n","        # img.shape: (1, 256, 256)\n","\n","        # labels\n","        label = self.train_df[self.train_df.patient_id == patient_id].values[0][1:-1]\n","        kidney = np.argmax(label[4:7], keepdims=False)\n","        liver = np.argmax(label[7:10], keepdims=False)\n","        spleen = np.argmax(label[10:], keepdims=False)\n","\n","        return {\n","            'patient_id': patient_id,\n","            'image': img,\n","            'kidney': kidney,\n","            'liver': liver,\n","            'spleen': spleen,\n","        }\n","\n","    def _fetch_and_sample_train_images(self, img_dirs, stride):\n","        \"\"\"\n","        Fetches and samples at least one training image per series from the training directories.\n","        \"\"\"\n","        print('Fetching and sampling training images...')\n","        paths = []\n","        patients_to_series_to_img_paths = defaultdict(lambda: defaultdict(list))\n","        for img_dir in img_dirs:\n","            for filename in tqdm(os.listdir(img_dir)):\n","                patient_id, series_id, _ = filename.split('_')\n","                patients_to_series_to_img_paths[patient_id][series_id].append(os.path.join(img_dir, filename))\n","\n","            for patient_id, series_to_img_paths in patients_to_series_to_img_paths.items():\n","                for series_id, imgs in series_to_img_paths.items():\n","                    # sort by instance number\n","                    sorted_img_paths = sorted(imgs, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n","                    start_index = int(len(sorted_img_paths) * self.slice_start)\n","                    end_index = int(len(sorted_img_paths) * (self.slice_start + 0.2))\n","                    roi = sorted_img_paths[start_index:end_index]\n","                    for img_path in roi[::stride]:\n","                        paths.append(img_path)\n","\n","        return paths\n","\n","    def _process_img(self, img_path):\n","        image = cv2.imread(img_path)\n","        # image = image.astype('float32') / 255\n","        image = (image.astype('float32') * 255).astype('uint8')\n","        greyscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        greyscale = cv2.resize(greyscale, (256, 256))\n","        return greyscale\n","\n","    def get_one_fold(self, fold=0):\n","        train_indices, val_indices = self.fold_data[fold]\n","        train_data = Subset(self, train_indices)\n","        val_data = Subset(self, val_indices)\n","        return train_data, val_data\n","\n","\n","class AbdominalBEData(Dataset):\n","\n","    def __init__(self, cfg, train_df, data_path, b_e_pos, sample_b_e_neg, apply_aug=True, num_fold=5):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.train_df = train_df\n","        self.b_e_data = pd.concat([b_e_pos, sample_b_e_neg])\n","        self.train_img_paths = self._fetch_train_image_paths(data_path, self.b_e_data)\n","        self.augmentation = apply_aug\n","\n","        self.gkf = GroupKFold(n_splits=num_fold)\n","        groups = np.array([os.path.basename(img_path).split('_')[0] for img_path in self.train_img_paths])\n","        self.fold_data = list(self.gkf.split(self.train_img_paths, groups=groups))\n","\n","        self.normalize = Compose([\n","            # Resize((256, 256), antialias=True),\n","            # RandomHorizontalFlip(),  # Randomly flip images left-right\n","            # ColorJitter(brightness=0.2),  # Randomly adjust brightness\n","            # ColorJitter(contrast=0.2),  # Randomly adjust contrast\n","            # RandomAffine(degrees=0, shear=10),  # Apply shear transformation\n","            # RandomAffine(degrees=0, scale=(0.8, 1.2)),  # Apply zoom transformation\n","            # RandomErasing(p=0.2, scale=(0.02, 0.2)),  # Coarse dropout\n","            ToTensor(),\n","        ])\n","\n","        # augmentation\n","        # flip\n","        self.aug_h_flip = A.HorizontalFlip(p=0.5)\n","        self.aug_v_flip = A.VerticalFlip(p=0.5)\n","        # elastic and grid\n","        self.aug_distortion = A.GridDistortion(p=0.5)\n","        self.aug_elastic = A.ElasticTransform(p=0.5)\n","        # affine\n","        self.aug_affine = A.Affine(\n","            scale=(0.8, 1.2),\n","            translate_percent=(0.0, 0.1),\n","            rotate=(-35, 35),\n","            shear=(-15, 15),\n","            p=0.5)\n","        # self.aug_affine = A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.8)\n","        # clahe\n","        self.aug_clahe = A.CLAHE(p=0.5)\n","        # bright\n","        self.aug_bright = A.OneOf([\n","            A.RandomGamma(gamma_limit=(60, 140), p=0.5),\n","            A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.5)\n","        ], p=0.5)\n","        # cutout\n","        self.aug_cutout = A.CoarseDropout(max_height=8, max_width=8, p=0.5)\n","        # randomcrop\n","        self.aug_randomcrop = A.RandomResizedCrop(\n","            height=256,\n","            width=256,\n","            scale=(0.8, 1.0),\n","            ratio=(3/4, 4/3),\n","            p=0.5)\n","\n","    def __len__(self):\n","        return len(self.train_img_paths)\n","\n","    def __getitem__(self, idx):\n","        sample_img_path = self.train_img_paths[idx]\n","        patient_id = int(os.path.basename(sample_img_path).split('_')[0])\n","\n","        # preprocess image\n","        img = self._process_img(sample_img_path)\n","        # img.shape: (256, 256)\n","\n","        # augmentation\n","        if self.augmentation:\n","            img = self.aug_h_flip(image=img)[\"image\"]\n","            img = self.aug_v_flip(image=img)[\"image\"]\n","            img = self.aug_distortion(image=img)[\"image\"]\n","            img = self.aug_clahe(image=img)[\"image\"]\n","            img = self.aug_affine(image=img)[\"image\"]\n","            img = self.aug_bright(image=img)[\"image\"]\n","            img = self.aug_cutout(image=img)[\"image\"]\n","            img = self.aug_randomcrop(image=img)[\"image\"]\n","\n","        img = img.astype('float32') / 255\n","        # img.shape: (256, 256)\n","\n","        img = torch.tensor(img, dtype=torch.float).unsqueeze(dim=0)\n","        # img.shape: (1, 256, 256)\n","        if self.cfg['model']['model_name'] == 'maxvit_tiny_tf_384.in1k':\n","            img = Compose([Resize((384, 384), antialias=True)])(img)\n","        img = self.normalize(img)\n","        # img.shape: (1, 256, 256)\n","\n","        # labels\n","        bowel = self.b_e_data[self.b_e_data.filename == sample_img_path].bowel.values[0]\n","        extravasation = self.b_e_data[self.b_e_data.filename == sample_img_path].extravasation.values[0]\n","\n","        return {\n","            'patient_id': patient_id,\n","            'image': img,\n","            'bowel': bowel,\n","            'extravasation': extravasation,\n","        }\n","\n","    def _fetch_train_image_paths(self, data_path, b_e_data):\n","        # get paths from both b_e_pos and sample_b_e_neg\n","        paths = []\n","        # add base_path to filename\n","        b_e_data['filename'] = b_e_data['filename'].apply(lambda x: os.path.join(data_path, x))\n","        paths.extend(b_e_data['filename'])\n","        # shuffle\n","        random.shuffle(paths)\n","        return paths\n","\n","    def _process_img(self, img_path):\n","        image = cv2.imread(img_path)\n","        # image = image.astype('float32') / 255\n","        image = (image.astype('float32') * 255).astype('uint8')\n","        greyscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        greyscale = cv2.resize(greyscale, (256, 256))\n","        return greyscale\n","\n","    def get_one_fold(self, fold=0):\n","        train_indices, val_indices = self.fold_data[fold]\n","        train_data = Subset(self, train_indices)\n","        val_data = Subset(self, val_indices)\n","        return train_data, val_data\n"]},{"cell_type":"markdown","metadata":{},"source":["## Model Architecture ##"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-01T15:36:15.999802Z","iopub.status.busy":"2023-10-01T15:36:15.999217Z","iopub.status.idle":"2023-10-01T15:36:16.020413Z","shell.execute_reply":"2023-10-01T15:36:16.019548Z","shell.execute_reply.started":"2023-10-01T15:36:15.999774Z"},"trusted":true},"outputs":[],"source":["# Model Architecure\n","class KLSNet(pl.LightningModule):\n","\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.backbone = timm.create_model(\n","            model_name=cfg['model']['model_name'],\n","            pretrained=cfg['model']['pretrained'],\n","            in_chans=cfg['model']['in_chans'],\n","            num_classes=cfg['model']['num_classes'],\n","            global_pool=cfg['model']['global_pool'],\n","            drop_rate=cfg[\"model\"][\"drop_rate\"],\n","            drop_path_rate=cfg[\"model\"][\"drop_path_rate\"],\n","        )\n","        # for param in self.backbone.parameters():\n","        #     param.requires_grad = False\n","\n","        self.in_features = self.backbone.num_features  # 1280\n","        hidden_dim = cfg['model']['hidden_dim']\n","        self.neck = nn.Sequential(\n","            nn.Linear(self.in_features, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(cfg['model']['p_dropout']),\n","        )\n","\n","        self.kidney = nn.Linear(hidden_dim, 3)\n","        self.liver = nn.Linear(hidden_dim, 3)\n","        self.spleen = nn.Linear(hidden_dim, 3)\n","\n","        self.cce = nn.CrossEntropyLoss(label_smoothing=0.05, weight=torch.tensor(cfg['model']['kls_weights']))\n","\n","        self.train_epoch_loss = []\n","        self.val_epoch_loss = []\n","        self.probs = defaultdict(list)\n","        self.targets = defaultdict(list)\n","        self.auc_scores = dict()\n","\n","    def forward(self, x):\n","        # extract features\n","        x = self.backbone(x)\n","        x = self.neck(x)\n","\n","        # output logits\n","        kidney = self.kidney(x)\n","        liver = self.liver(x)\n","        spleen = self.spleen(x)\n","\n","        return kidney, liver, spleen\n","\n","    def training_step(self, batch, batch_idx):\n","        inputs = batch['image']\n","        kidney = batch['kidney']\n","        liver = batch['liver']\n","        spleen = batch['spleen']\n","\n","        k, l, s = self.forward(inputs)\n","        k_loss = self.cce(k, kidney)\n","        l_loss = self.cce(l, liver)\n","        s_loss = self.cce(s, spleen)\n","        loss = k_loss + l_loss + s_loss\n","        self.train_epoch_loss.append(loss.item())\n","\n","        self.log('train_loss', loss, prog_bar=True, logger=True, on_epoch=True, on_step=True, sync_dist=True)\n","        return loss\n","\n","    # def on_train_epoch_end(self):\n","    #     avg_loss = np.mean(self.train_epoch_loss)\n","    #     self.log('avg_train_loss', avg_loss, prog_bar=True)\n","    #     self.train_epoch_loss.clear()\n","\n","    def validation_step(self, batch, batch_idx):\n","        inputs = batch['image']\n","        kidney = batch['kidney']\n","        liver = batch['liver']\n","        spleen = batch['spleen']\n","\n","        k, l, s = self.forward(inputs)\n","        k_loss = self.cce(k, kidney)\n","        l_loss = self.cce(l, liver)\n","        s_loss = self.cce(s, spleen)\n","        loss = k_loss + l_loss + s_loss\n","        self.val_epoch_loss.append(loss.item())\n","\n","        self.probs['k'].extend(F.softmax(k, dim=1).detach().cpu().numpy())\n","        self.probs['l'].extend(F.softmax(l, dim=1).detach().cpu().numpy())\n","        self.probs['s'].extend(F.softmax(s, dim=1).detach().cpu().numpy())\n","        self.targets['k'].extend(kidney.detach().cpu().numpy())\n","        self.targets['l'].extend(liver.detach().cpu().numpy())\n","        self.targets['s'].extend(spleen.detach().cpu().numpy())\n","\n","        self.log('val_loss', loss, prog_bar=True, logger=True, on_epoch=True, on_step=True, sync_dist=True)\n","        return loss\n","\n","    def on_validation_epoch_end(self):\n","        avg_loss = np.mean(self.val_epoch_loss)\n","\n","        for t in ['k', 'l', 's']:\n","            self.auc_scores[t] = roc_auc_score(\n","                self.targets.get(t),\n","                self.probs.get(t),\n","                multi_class='ovo', labels=[0, 1, 2])\n","\n","        # self.log('avg_val_loss', avg_loss, prog_bar=True)\n","        self.log('val_auc_score_k', self.auc_scores.get('k'), prog_bar=True, sync_dist=True)\n","        self.log('val_auc_score_l', self.auc_scores.get('l'), prog_bar=True, sync_dist=True)\n","        self.log('val_auc_score_s', self.auc_scores.get('s'), prog_bar=True, sync_dist=True)\n","        self.val_epoch_loss.clear()\n","        self.probs.clear()\n","        self.targets.clear()\n","        self.auc_scores.clear()\n","\n","    def configure_optimizers(self):\n","        optimizer = AdamW(self.parameters(), lr=float(self.cfg['model']['lr']))\n","        # optimizer = AdamW(filter(lambda p: p.requires_grad, self.parameters()), lr=float(self.cfg['model']['lr']))\n","        return optimizer\n","\n","    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n","        pass\n","\n","\n","# Model Architecure\n","class BENet(pl.LightningModule):\n","\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.backbone = timm.create_model(\n","            model_name=cfg['model']['model_name'],\n","            pretrained=cfg['model']['pretrained'],\n","            in_chans=cfg['model']['in_chans'],\n","            num_classes=cfg['model']['num_classes'],\n","            global_pool=cfg['model']['global_pool'],\n","            drop_rate=cfg[\"model\"][\"drop_rate\"],\n","            drop_path_rate=cfg[\"model\"][\"drop_path_rate\"],\n","        )\n","        # for param in self.backbone.parameters():\n","        #     param.requires_grad = False\n","\n","        self.in_features = self.backbone.num_features  # 1280\n","        hidden_dim = cfg['model']['hidden_dim']\n","        self.neck = nn.Sequential(\n","            nn.Linear(self.in_features, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(cfg['model']['p_dropout']),\n","        )\n","\n","        self.bowel = nn.Linear(hidden_dim, 2)\n","        self.extravasation = nn.Linear(hidden_dim, 2)\n","\n","        self.cce_b = nn.CrossEntropyLoss(label_smoothing=0.05, weight=torch.tensor(cfg['model']['b_weights']))\n","        self.cce_e = nn.CrossEntropyLoss(label_smoothing=0.05, weight=torch.tensor(cfg['model']['e_weights']))\n","\n","        self.train_epoch_loss = []\n","        self.val_epoch_loss = []\n","        self.probs = defaultdict(list)\n","        self.targets = defaultdict(list)\n","        self.auc_scores = dict()\n","\n","    def forward(self, x):\n","        # extract features\n","        x = self.backbone(x)\n","        x = self.neck(x)\n","\n","        # output logits\n","        bowel = self.bowel(x)\n","        extravsation = self.extravasation(x)\n","\n","        return bowel, extravsation\n","\n","    def training_step(self, batch, batch_idx):\n","        inputs = batch['image']\n","        bowel = batch['bowel']\n","        extravasation = batch['extravasation']\n","\n","        b, e = self.forward(inputs)\n","        b_loss = self.cce_b(b, bowel)\n","        e_loss = self.cce_e(e, extravasation)\n","        loss = b_loss + e_loss\n","        self.train_epoch_loss.append(loss.item())\n","\n","        self.log('train_loss', loss, prog_bar=True, logger=True, on_epoch=True, on_step=True, sync_dist=True)\n","        return loss\n","\n","    # def on_train_epoch_end(self):\n","    #     avg_loss = np.mean(self.train_epoch_loss)\n","    #     self.log('avg_train_loss', avg_loss, prog_bar=True)\n","    #     self.train_epoch_loss.clear()\n","\n","    def validation_step(self, batch, batch_idx):\n","        inputs = batch['image']\n","        bowel = batch['bowel']\n","        extravasation = batch['extravasation']\n","\n","        b, e = self.forward(inputs)\n","        b_loss = self.cce_b(b, bowel)\n","        e_loss = self.cce_e(e, extravasation)\n","        loss = b_loss + e_loss\n","        self.val_epoch_loss.append(loss.item())\n","\n","        self.probs['b'].extend(F.softmax(b, dim=1).detach().cpu().numpy())\n","        self.probs['e'].extend(F.softmax(e, dim=1).detach().cpu().numpy())\n","        self.targets['b'].extend(bowel.detach().cpu().numpy())\n","        self.targets['e'].extend(extravasation.detach().cpu().numpy())\n","\n","        self.log('val_loss', loss, prog_bar=True, logger=True, on_epoch=True, on_step=True, sync_dist=True)\n","        return loss\n","\n","    def on_validation_epoch_end(self):\n","        avg_loss = np.mean(self.val_epoch_loss)\n","\n","        for t in ['b', 'e']:\n","            y_true = np.ravel(self.targets.get(t))\n","            prob_array = np.array(self.probs.get(t))\n","            if len(np.unique(y_true)) != 2:\n","                return -1\n","            self.auc_scores[t] = roc_auc_score(y_true, prob_array[:, 1])\n","\n","        # self.log('avg_val_loss', avg_loss, prog_bar=True)\n","        self.log('val_auc_score_b', self.auc_scores.get('b'), prog_bar=True, sync_dist=True)\n","        self.log('val_auc_score_e', self.auc_scores.get('e'), prog_bar=True, sync_dist=True)\n","        self.val_epoch_loss.clear()\n","        self.probs.clear()\n","        self.targets.clear()\n","        self.auc_scores.clear()\n","\n","    def configure_optimizers(self):\n","        optimizer = AdamW(self.parameters(), lr=float(self.cfg['model']['lr']))\n","        # optimizer = AdamW(filter(lambda p: p.requires_grad, self.parameters()), lr=float(self.cfg['model']['lr']))\n","        return optimizer\n","\n","    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n","        pass\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Training and Validating ##"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-10-01T15:36:16.049007Z","iopub.status.busy":"2023-10-01T15:36:16.048711Z","iopub.status.idle":"2023-10-01T15:36:35.907240Z","shell.execute_reply":"2023-10-01T15:36:35.906237Z","shell.execute_reply.started":"2023-10-01T15:36:16.048981Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["STRIDE: 1000\n","\n","N_FOLDS: 5\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"818dce70226d4c63accbd643005191fe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/193065 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce95428d15c84ab69eca893f34de563d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/188213 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97f58439a77d47a49d2e930fbb2176bf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/198102 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25d0d241833c4b8b96366ecb457c9b85","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/177646 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4fe030d676044b16aeecc78d6b57c002","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/187164 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9901f0d4e0a04cbfbd43e46468e72ffc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/186309 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72535b40ede44215bd154f5f07dbfd58","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/192002 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d2c3f93ce1847d49c961d850bb0efba","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/178152 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset size: 21616\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n","\n","  warnings.warn(\n"]}],"source":["# prepare dataset\n","print(\"Preparing dataset...\")\n","train_df = pd.read_csv(TRAIN_DF_PATH)\n","# kidney, liver, spleen dataset\n","if cfg['model']['model_type'] == 'kls':\n","    print('n_folds:', cfg['data']['n_folds'])\n","    print('kls_slice_start:', cfg['data']['kls_slice_start'])\n","    print('kls_stride:', cfg['data']['kls_stride'])\n","    print('apply_aug:', cfg['data']['apply_aug'])\n","    dataset = AbdominalKLSData(\n","        train_df,\n","        TRAIN_IMG_PATHS,\n","        slice_start=cfg['data']['kls_slice_start'],\n","        stride=cfg['data']['kls_stride'],\n","        apply_aug=cfg['data']['apply_aug'],\n","        num_fold=cfg['data']['n_folds']\n","    )\n","    print('KLSData size:', len(dataset))\n","    if cfg['general']['use_wandb']:\n","        wandb.log({'kls_data_size': len(dataset)})\n","else:\n","    # bowel, extravasation dataset\n","    print('apply_aug:', cfg['data']['apply_aug'])\n","    b_e_pos = pd.read_csv(B_E_POS_PATH)\n","    sample_b_e_neg = pd.read_csv(B_E_NEG_PATH)\n","    dataset = AbdominalBEData(\n","        train_df,\n","        BASE_PATH, # Caution! DATA_PATH if on ec2\n","        b_e_pos,\n","        sample_b_e_neg,\n","        apply_aug=cfg['data']['apply_aug'],\n","        num_fold=cfg['data']['n_folds']\n","    )\n","    print('BEData size:', len(dataset))\n","    if cfg['general']['use_wandb']:\n","        wandb.log({'b_e_data_size': len(dataset)})\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# provided by competition organizer\n","import numpy as np\n","import pandas as pd\n","import pandas.api.types\n","import sklearn.metrics\n","\n","\n","class ParticipantVisibleError(Exception):\n","    pass\n","\n","\n","def normalize_probabilities_to_one(df: pd.DataFrame, group_columns: list) -> pd.DataFrame:\n","    # Normalize the sum of each row's probabilities to 100%.\n","    # 0.75, 0.75 => 0.5, 0.5\n","    # 0.1, 0.1 => 0.5, 0.5\n","    row_totals = df[group_columns].sum(axis=1)\n","    if row_totals.min() == 0:\n","        raise ParticipantVisibleError('All rows must contain at least one non-zero prediction')\n","    for col in group_columns:\n","        df[col] /= row_totals\n","    return df\n","\n","\n","def calc_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str = '') -> float:\n","    '''\n","    Pseudocode:\n","    1. For every label group (liver, bowel, etc):\n","        - Normalize the sum of each row's probabilities to 100%.\n","        - Calculate the sample weighted log loss.\n","    2. Derive a new any_injury label by taking the max of 1 - p(healthy) for each label group\n","    3. Calculate the sample weighted log loss for the new label group\n","    4. Return the average of all of the label group log losses as the final score.\n","    '''\n","#     del solution[row_id_column_name]\n","#     del submission[row_id_column_name]\n","\n","    # Run basic QC checks on the inputs\n","    if not pandas.api.types.is_numeric_dtype(submission.values):\n","        raise ParticipantVisibleError('All submission values must be numeric')\n","\n","    if not np.isfinite(submission.values).all():\n","        raise ParticipantVisibleError('All submission values must be finite')\n","\n","    if solution.min().min() < 0:\n","        raise ParticipantVisibleError('All labels must be at least zero')\n","    if submission.min().min() < 0:\n","        raise ParticipantVisibleError('All predictions must be at least zero')\n","\n","    # Calculate the label group log losses\n","    binary_targets = ['bowel', 'extravasation']\n","    triple_level_targets = ['kidney', 'liver', 'spleen']\n","    all_target_categories = binary_targets + triple_level_targets\n","\n","    label_group_losses = []\n","    for category in all_target_categories:\n","        if category in binary_targets:\n","            col_group = [f'{category}_healthy', f'{category}_injury']\n","        else:\n","            col_group = [f'{category}_healthy', f'{category}_low', f'{category}_high']\n","\n","        solution = normalize_probabilities_to_one(solution, col_group)\n","\n","        for col in col_group:\n","            if col not in submission.columns:\n","                raise ParticipantVisibleError(f'Missing submission column {col}')\n","        submission = normalize_probabilities_to_one(submission, col_group)\n","        label_group_losses.append(\n","            sklearn.metrics.log_loss(\n","                y_true=solution[col_group].values,\n","                y_pred=submission[col_group].values,\n","                sample_weight=solution[f'{category}_weight'].values\n","            )\n","        )\n","\n","    # Derive a new any_injury label by taking the max of 1 - p(healthy) for each label group\n","    healthy_cols = [x + '_healthy' for x in all_target_categories]\n","    any_injury_labels = (1 - solution[healthy_cols]).max(axis=1)\n","    any_injury_predictions = (1 - submission[healthy_cols]).max(axis=1)\n","    any_injury_loss = sklearn.metrics.log_loss(\n","        y_true=any_injury_labels.values,\n","        y_pred=any_injury_predictions.values,\n","        sample_weight=solution['any_injury_weight'].values\n","    )\n","\n","    label_group_losses.append(any_injury_loss)\n","    return np.mean(label_group_losses)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def predict(model, test_dataloader):\n","    model.eval()\n","    test_predictions = []\n","    with torch.no_grad():\n","        for batch_idx, batch_data in tqdm(enumerate(test_dataloader)):\n","            image = batch_data['image']\n","            patient_id = batch_data['patient_id']\n","            b, e, k, l, s = model(image)\n","\n","            # Apply activations to get probabilities\n","            b_probs, e_probs, k_probs, l_probs, s_probs = map(\n","                lambda x: F.softmax(x, dim=1),\n","                [b, e, k, l, s]\n","            )\n","\n","            # Transfer probabilities back to CPU\n","            b_probs, e_probs, k_probs, l_probs, s_probs = map(\n","                lambda x: x.cpu().numpy().astype(np.float64),\n","                [b_probs, e_probs, k_probs, l_probs, s_probs]\n","            )\n","\n","            # Get one prediction per series in the batch\n","            for i in range(b_probs.shape[0]):  # Assuming all arrays have the same size\n","                test_predictions.append([\n","                    int(patient_id[i]),\n","                    *b_probs[i],\n","                    *e_probs[i],\n","                    *k_probs[i],\n","                    *l_probs[i],\n","                    *s_probs[i]\n","                ])\n","\n","    column_names = ['patient_id',\n","                    'bowel_healthy', 'bowel_injury',\n","                    'extravasation_healthy', 'extravasation_injury',\n","                    'kidney_healthy', 'kidney_low', 'kidney_high',\n","                    'liver_healthy', 'liver_low', 'liver_high',\n","                    'spleen_healthy', 'spleen_low', 'spleen_high']\n","\n","    df_preds = pd.DataFrame(test_predictions, columns=column_names)\n","    df_preds = df_preds.groupby('patient_id').mean().reset_index()\n","\n","    return df_preds\n","\n","\n","def calc_cv_score(model, val_dataloader, train_df):\n","    print(\"Calculating CV score...\")\n","    preds_df = predict(model, val_dataloader)\n","    patients = preds_df[['patient_id']]\n","    solution_df = pd.merge(patients, train_df, on='patient_id', how='left')\n","    # add weights\n","    solution_df['bowel_weight'] = 1\n","    solution_df['extravasation_weight'] = 1\n","    solution_df['kidney_weight'] = 1\n","    solution_df['liver_weight'] = 1\n","    solution_df['spleen_weight'] = 1\n","    solution_df['any_injury_weight'] = 1\n","\n","    score = calc_score(solution_df, preds_df)\n","    print('CV score:', score)\n","    if cfg['general']['use_wandb']:\n","        wandb.log({'cv_score': score})\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-10-01T15:36:35.910573Z","iopub.status.busy":"2023-10-01T15:36:35.910012Z","iopub.status.idle":"2023-10-01T15:45:57.022502Z","shell.execute_reply":"2023-10-01T15:45:57.021265Z","shell.execute_reply.started":"2023-10-01T15:36:35.910526Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BATCH_SIZE: 16\n","\n","NUM_EPOCHS: 2\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5dea5a02fc2343ab9c2ba158ce3810e9","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/86.5M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Fold 0\n"]}],"source":["# train and validate\n","print(f\"Training {cfg['model']['model_type']}...\")\n","print('batch_size:', cfg['data']['batch_size'])\n","print('max_epochs:', cfg['pl_params']['max_epochs'])\n","\n","print(f\"folds: {cfg['data']['fold_i']}\")\n","for fold_i in cfg['data']['fold_i']:\n","    print(f'fold {fold_i}')\n","\n","    if cfg['model']['model_type'] == 'kls':\n","        model = KLSNet(cfg)\n","    else:\n","        model = BENet(cfg)\n","\n","    train_data, val_data = dataset.get_one_fold(fold_i)\n","    train_dataloader = DataLoader(\n","        train_data, batch_size=cfg['data']['batch_size'],\n","        shuffle=True, num_workers=num_workers, pin_memory=True)\n","    val_dataloader = DataLoader(\n","        val_data, batch_size=cfg['data']['batch_size'],\n","        shuffle=False, num_workers=num_workers, pin_memory=True)\n","\n","    # train for some epochs\n","    trainer = Trainer(\n","        logger=logger,\n","        **cfg['pl_params'], \n","    )\n","    trainer.fit(\n","        model,\n","        train_dataloader,\n","        val_dataloader,\n","    )\n","\n","    # calc cv score\n","    if cfg['data']['calc_cv_score']:\n","        calc_cv_score(model, val_dataloader, train_df)\n","\n","    if cfg['general']['use_wandb']:\n","        wandb.finish()\n","\n","    # save model\n","    torch.save(model, f\"{MODEL_PATH}_fold{fold_i}.pt\")\n","    del model\n","    torch.cuda.empty_cache()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":4}
