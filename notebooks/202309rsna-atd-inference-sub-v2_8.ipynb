{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:12:02.991005Z","iopub.status.busy":"2023-09-28T08:12:02.990586Z","iopub.status.idle":"2023-09-28T08:12:02.995912Z","shell.execute_reply":"2023-09-28T08:12:02.994635Z","shell.execute_reply.started":"2023-09-28T08:12:02.990974Z"},"trusted":true},"outputs":[],"source":["###\n","# is_on_kaggle = True\n","is_on_kaggle = False\n","###\n","is_debugging = True\n","# is_debugging = False"]},{"cell_type":"markdown","metadata":{},"source":["## Import ##"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:12:03.001564Z","iopub.status.busy":"2023-09-28T08:12:03.001085Z","iopub.status.idle":"2023-09-28T08:12:03.012989Z","shell.execute_reply":"2023-09-28T08:12:03.011447Z","shell.execute_reply.started":"2023-09-28T08:12:03.001531Z"},"trusted":true},"outputs":[],"source":["# import packages\n","import os\n","import multiprocessing\n","from pathlib import Path\n","import random\n","from collections import defaultdict\n","from glob import glob\n","import pickle\n","from joblib import Parallel, delayed\n","import gc\n","from tqdm.notebook import tqdm\n","from tabulate import tabulate\n","import yaml\n","import datetime\n","from logging import getLogger\n","import wandb\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold, GroupKFold, StratifiedGroupKFold\n","from sklearn.metrics import accuracy_score, roc_auc_score\n","\n","import cv2\n","import pydicom\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.optim import Adam, AdamW\n","from torchvision import models\n","# from torchvision.transforms import (Compose, Resize, ToTensor, Normalize, RandomHorizontalFlip,)\n","import torchvision.transforms.v2 as t\n","from torchvision.transforms.v2 import (Resize, Compose, RandomHorizontalFlip, \n","                                       ColorJitter, RandomAffine, RandomErasing, ToTensor)\n","import pytorch_lightning as pl\n","from pytorch_lightning import seed_everything\n","from pytorch_lightning import Trainer\n","from pytorch_lightning.loggers import WandbLogger\n","import timm\n","import albumentations as A\n"]},{"cell_type":"markdown","metadata":{},"source":["## Constants ##"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cfg = {\n","    'general': {\n","        'project_name': '202309-rsna-atd',\n","        'inference_version': 'v2-8',\n","        'seed': 42,\n","    },\n","    'data': {\n","        'n_folds': 5, \n","        'fold_i': 0, \n","        'batch_size_inference': 16, \n","        'kls_slice_start': 0.6, \n","        'b_e_1_slice_start': 0.0, \n","        'b_e_2_slice_start': 0.0, \n","        'kls_stride': 4, \n","        'b_e_1_stride': 16, \n","        'b_e_2_stride': 48, \n","        'calc_cv_score': False, \n","        'apply_aug': True,\n","    }, \n","    'model': {\n","        'kls_model_name': 'tf_efficientnetv2_s',\n","        'b_e_model_name_1': 'tf_efficientnetv2_s',\n","        'b_e_model_name_2': 'maxvit_tiny_tf_384.in1k',\n","        'pretrained': False, # for inference\n","        'in_chans': 1, \n","        'num_classes': 0, # to use as backbone\n","        'global_pool': 'max',\n","        'drop_rate': 0.8, \n","        'drop_path_rate': 0.2, \n","        'kls_weights': [1.0, 8.0, 16.0],  # healty, low, high\n","        'b_weights': [1.0, 8.0],  # healthy, injury\n","        'e_weights': [1.0, 24.0],  # healthy, injury\n","        'hidden_dim': 128,\n","        'p_dropout': 0.3,\n","        'lr': 1.0e-4, \n","    },\n","    'pl_params': {\n","        'accelerator': 'auto',\n","        'precision': 16,  # 16 or 32\n","        'enable_progress_bar': True, \n","    }\n","}\n","\n","if is_debugging:\n","    cfg['data']['kls_stride'] = 1000\n","    cfg['data']['b_e_1_stride'] = 1000\n","    cfg['data']['b_e_2_stride'] = 1000\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Paths ##"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["BASE_PATH = '.' if not is_on_kaggle else '/kaggle/input/rsna-2023-abdominal-trauma-detection'\n","KLS_TEST_DATA_DIR = '../kls_test_data_v2_8'\n","B_E_1_TEST_DATA_DIR = '../b_e_1_test_data_v2_8'\n","B_E_2_TEST_DATA_DIR = '../b_e_2_test_data_v2_8'\n","KLS_MODEL_PATH = f\"../models/{cfg['model']['kls_model_name']}_exp005_kls_fold{cfg['data']['fold_i']}_aug.pt\"\n","B_E_MODEL_1_PATH = f\"../models/{cfg['model']['b_e_model_name_1']}_exp010_b_e_fold{cfg['data']['fold_i']}.pt\"\n","B_E_MODEL_2_PATH = f\"../models/{cfg['model']['b_e_model_name_2']}_exp011_b_e_fold{cfg['data']['fold_i']}.pt\"\n","\n","if is_on_kaggle:\n","    TEST_DATA_DIR = f'{BASE_PATH}/test_images'\n","    df_dicom_test = pd.read_parquet(f'{BASE_PATH}/test_dicom_tags.parquet')\n","    sample_submission = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')\n","    KLS_TEST_DATA_DIR = './kls_test_data_v2_8'\n","    B_E_1_TEST_DATA_DIR = './b_e_1_test_data_v2_8'\n","    B_E_2_TEST_DATA_DIR = './b_e_2_test_data_v2_8'\n","    KLS_MODEL_PATH = f\"/kaggle/input/models-{cfg['general']['inference_version']}/{cfg['model']['kls_model_name']}_exp005_kls_fold{cfg['data']['fold_i']}_aug.pt\"\n","    B_E_MODEL_1_PATH = f\"/kaggle/input/models-{cfg['general']['inference_version']}/{cfg['model']['b_e_model_name_1']}_exp010_b_e_fold{cfg['data']['fold_i']}.pt\"\n","    B_E_MODEL_2_PATH = f\"/kaggle/input/models-{cfg['general']['inference_version']}/{cfg['model']['b_e_model_name_2']}_exp011_b_e_fold{cfg['data']['fold_i']}.pt\"\n","\n","os.makedirs(KLS_TEST_DATA_DIR, exist_ok=True)\n","os.makedirs(B_E_1_TEST_DATA_DIR, exist_ok=True)\n","os.makedirs(B_E_2_TEST_DATA_DIR, exist_ok=True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:12:03.016491Z","iopub.status.busy":"2023-09-28T08:12:03.015643Z","iopub.status.idle":"2023-09-28T08:12:03.023802Z","shell.execute_reply":"2023-09-28T08:12:03.022688Z","shell.execute_reply.started":"2023-09-28T08:12:03.016460Z"},"trusted":true},"outputs":[],"source":["# misc functions\n","torch.cuda.empty_cache()\n","# multiprocessing.set_start_method('spawn', force=True)\n","seed_everything(cfg['general']['seed'], workers=True)\n","num_workers = os.cpu_count() if is_on_kaggle else 0\n","gpu_count = torch.cuda.device_count()\n","print('num_workers:', num_workers)\n","print('gpu_count:', gpu_count)\n","\n","def random_seed(seed=42):\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    torch.cuda.manual_seed(seed)    \n","\n","random_seed(cfg['general']['seed'])"]},{"cell_type":"markdown","metadata":{},"source":["## Preparing test data ##"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:12:03.085573Z","iopub.status.busy":"2023-09-28T08:12:03.085185Z","iopub.status.idle":"2023-09-28T08:12:03.103316Z","shell.execute_reply":"2023-09-28T08:12:03.102286Z","shell.execute_reply.started":"2023-09-28T08:12:03.085542Z"},"trusted":true},"outputs":[],"source":["# ## check to solve scoring error\n","# if is_on_kaggle:\n","#     TRAIN_DATA_DIR = f'{BASE_PATH}/train_images'\n","#     TRAIN_LABEL = f'{BASE_PATH}/train.csv'\n","#     train_series_meta = pd.read_csv(f'{BASE_PATH}/train_series_meta.csv')\n","#     train_df = pd.read_csv(TRAIN_LABEL)\n","\n","#     # use train data instead of test data\n","#     TEST_DATA_DIR = TRAIN_DATA_DIR\n","#     sample_submission = train_df\n","# #     unique_patients = train_series_meta.patient_id.unique()\n","# #     sample_submission = pd.DataFrame(unique_patients, columns=['patient_id'])\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:12:03.105227Z","iopub.status.busy":"2023-09-28T08:12:03.104852Z","iopub.status.idle":"2023-09-28T08:12:03.115222Z","shell.execute_reply":"2023-09-28T08:12:03.111958Z","shell.execute_reply.started":"2023-09-28T08:12:03.105196Z"},"trusted":true},"outputs":[],"source":["def standardize_pixel_array(dcm: pydicom.dataset.FileDataset) -> np.ndarray:\n","    \"\"\"\n","    Source : https://www.kaggle.com/competitions/rsna-2023-abdominal-trauma-detection/discussion/427217\n","    \"\"\"\n","    # Correct DICOM pixel_array if PixelRepresentation == 1.\n","    pixel_array = dcm.pixel_array\n","    if dcm.PixelRepresentation == 1:\n","        bit_shift = dcm.BitsAllocated - dcm.BitsStored\n","        dtype = pixel_array.dtype \n","        pixel_array = (pixel_array << bit_shift).astype(dtype) >>  bit_shift\n","#         pixel_array = pydicom.pixel_data_handlers.util.apply_modality_lut(new_array, dcm)\n","\n","    intercept = float(dcm.RescaleIntercept)\n","    slope = float(dcm.RescaleSlope)\n","    center = int(dcm.WindowCenter)\n","    width = int(dcm.WindowWidth)\n","    low = center - width / 2\n","    high = center + width / 2    \n","    \n","    pixel_array = (pixel_array * slope) + intercept\n","    pixel_array = np.clip(pixel_array, low, high)\n","\n","    return pixel_array\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:12:03.117571Z","iopub.status.busy":"2023-09-28T08:12:03.117017Z","iopub.status.idle":"2023-09-28T08:12:03.129870Z","shell.execute_reply":"2023-09-28T08:12:03.128863Z","shell.execute_reply.started":"2023-09-28T08:12:03.117536Z"},"trusted":true},"outputs":[],"source":["def preprocess(patient, series, slice_start, slice_window, stride=10, size=256, flag='', test_data_dir='', save_folder=''):\n","    imgs = {}\n","    sorted_img_paths = sorted(glob(os.path.join(test_data_dir, patient, series, \"*.dcm\")), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n","    start_index = int(len(sorted_img_paths) * slice_start)\n","    end_index = int(len(sorted_img_paths) * (slice_start + slice_window))\n","    if flag == 'b_e_2':\n","        # slide = int(min(stride / 2, len(sorted_img_paths) / 2))\n","        slide = int(min(8, len(sorted_img_paths) / 2))\n","        start_index += slide\n","        end_index += slide\n","    if start_index == end_index:\n","        end_index += 1\n","    roi = sorted_img_paths[start_index:end_index]\n","    for f in roi[::stride]:\n","        # skip this corrupted file, test_images/3124/5842/514.dcm\n","        if f.split('/')[-3] == '3124' and f.split('/')[-2] == '5842' and f.split('/')[-1] == '514.dcm':\n","            continue\n","        dicom = pydicom.dcmread(f)\n","        pos_z = dicom[(0x20, 0x32)].value[-1]\n","        img = standardize_pixel_array(dicom)\n","        img = (img - img.min()) / (img.max() - img.min() + 1e-6)\n","        if dicom.PhotometricInterpretation == 'MONOCHROME1':\n","            img = 1 - img\n","        imgs[pos_z] = img\n","\n","    for i, k in enumerate(sorted(imgs.keys())):\n","        img = imgs[k]\n","        if size is not None:\n","            img = cv2.resize(img, (size, size))\n","        if isinstance(save_folder, str):\n","            cv2.imwrite(os.path.join(save_folder, f'{patient}_{series}_{i}.png'), (img * 255).astype(np.uint8))\n","        else:\n","            im = cv2.imencode('.png', (img * 255).astype(np.uint8))[1]\n","            save_folder.writestr(f'{patient}_{series}_{i:04d}.png', im)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:12:03.131998Z","iopub.status.busy":"2023-09-28T08:12:03.131394Z","iopub.status.idle":"2023-09-28T08:13:42.765718Z","shell.execute_reply":"2023-09-28T08:13:42.764684Z","shell.execute_reply.started":"2023-09-28T08:12:03.131963Z"},"trusted":true},"outputs":[],"source":["# kls\n","# preprocess all test images with multiprocessing\n","if is_on_kaggle:\n","    tasks = []\n","    for patient in os.listdir(TEST_DATA_DIR):\n","        # if len(os.listdir(os.path.join(TEST_DATA_DIR, patient))) == 0:\n","        #     continue\n","        for series in sorted(os.listdir(os.path.join(TEST_DATA_DIR, patient))):\n","            # if len(os.listdir(os.path.join(TEST_DATA_DIR, patient, series))) == 0:\n","            #     continue\n","            tasks.append((patient, series))\n","\n","    slice_start = cfg['data']['kls_slice_start']\n","    slice_window = 0.2\n","    stride = cfg['data']['kls_stride']\n","    print('len(tasks):', len(tasks))\n","    print('kls_slice_start:', slice_start)\n","    print('kls_stride:', stride)\n","    _ = Parallel(n_jobs=-1, backend='threading')(\n","        delayed(preprocess)(patient, series, slice_start, slice_window, stride, test_data_dir=TEST_DATA_DIR, save_folder=KLS_TEST_DATA_DIR)\n","        for patient, series in tqdm(tasks)\n","    )\n","    \n","    del _\n","    gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# b_e 1\n","# preprocess all test images with multiprocessing\n","if is_on_kaggle:\n","    slice_start = cfg['data']['b_e_1_slice_start']\n","    slice_window = 0.8\n","    stride = cfg['data']['b_e_1_stride']\n","    print('len(tasks):', len(tasks))\n","    print('b_e_slice_start:', slice_start)\n","    print('b_e_stride:', stride)\n","    _ = Parallel(n_jobs=-1, backend='threading')(\n","        delayed(preprocess)(patient, series, slice_start, slice_window, stride, \n","                            test_data_dir=TEST_DATA_DIR, save_folder=B_E_1_TEST_DATA_DIR)\n","        for patient, series in tqdm(tasks)\n","    )\n","    \n","    del _\n","    gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# b_e 2\n","# preprocess all test images with multiprocessing\n","if is_on_kaggle:\n","    flag = 'b_e_2'\n","    slice_start = cfg['data']['b_e_2_slice_start']\n","    slice_window = 0.8\n","    stride = cfg['data']['b_e_2_stride']\n","    print('len(tasks):', len(tasks))\n","    print('b_e_slice_start:', slice_start)\n","    print('b_e_stride:', stride)\n","    _ = Parallel(n_jobs=-1, backend='threading')(\n","        delayed(preprocess)(patient, series, slice_start, slice_window, stride, flag=flag, \n","                            test_data_dir=TEST_DATA_DIR, save_folder=B_E_2_TEST_DATA_DIR)\n","        for patient, series in tqdm(tasks)\n","    )\n","    \n","    del _\n","    gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:13:42.905393Z","iopub.status.busy":"2023-09-28T08:13:42.904580Z","iopub.status.idle":"2023-09-28T08:13:42.921069Z","shell.execute_reply":"2023-09-28T08:13:42.920000Z","shell.execute_reply.started":"2023-09-28T08:13:42.905347Z"},"trusted":true},"outputs":[],"source":["# dataset\n","class AbdominalKLSDataTest(Dataset):\n","    \n","    def __init__(self, cfg, model_name, test_img_dir, apply_aug=True):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.model_name = model_name\n","        self.augmentation = apply_aug\n","\n","        self.test_img_paths = self._fetch_test_img_paths(test_img_dir)\n","                \n","        self.normalize = Compose([\n","            # Resize((256, 256), antialias=True),\n","            # RandomHorizontalFlip(),  # Randomly flip images left-right\n","            # ColorJitter(brightness=0.2),  # Randomly adjust brightness\n","            # ColorJitter(contrast=0.2),  # Randomly adjust contrast\n","            # RandomAffine(degrees=0, shear=10),  # Apply shear transformation\n","            # RandomAffine(degrees=0, scale=(0.8, 1.2)),  # Apply zoom transformation\n","            # RandomErasing(p=0.2, scale=(0.02, 0.2)),  # Coarse dropout\n","            ToTensor(),\n","            # ToImageTensor(), \n","            # ConvertImageDtype(), \n","        ])\n","\n","        # augmentation\n","        # flip\n","        self.aug_h_flip = A.HorizontalFlip(p=0.5)\n","        self.aug_v_flip = A.VerticalFlip(p=0.5)\n","        # elastic and grid\n","        self.aug_distortion = A.GridDistortion(p=0.5)\n","        self.aug_elastic = A.ElasticTransform(p=0.5)\n","        # affine\n","        self.aug_affine = A.Affine(\n","            scale=(0.8, 1.2),\n","            translate_percent=(0.0, 0.2),\n","            rotate=(-45, 45),\n","            shear=(-15, 15),\n","            p=0.5)\n","        # self.aug_affine = A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.8)\n","        # clahe\n","        self.aug_clahe = A.CLAHE(p=0.5)\n","        # bright\n","        self.aug_bright = A.OneOf([\n","            A.RandomGamma(gamma_limit=(50, 150), p=0.5),\n","            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.5)\n","        ], p=0.5)\n","        # cutout\n","        self.aug_cutout = A.CoarseDropout(max_height=8, max_width=8, p=0.5)\n","        # randomcrop\n","        self.aug_randomcrop = A.RandomResizedCrop(\n","            height=256,\n","            width=256,\n","            scale=(0.8, 1.0),\n","            ratio=(3/4, 4/3),\n","            p=0.5)\n","    \n","    def __len__(self):\n","        return len(self.test_img_paths)\n","    \n","    def __getitem__(self, idx):\n","        sample_img_path = self.test_img_paths[idx]\n","        patient_id = int(os.path.basename(sample_img_path).split('_')[0])\n","\n","        # preprocess image\n","        img = self._process_img(sample_img_path)\n","        # img.shape: (256, 256)\n","\n","        # augmentation\n","        if self.augmentation:\n","            img = self.aug_h_flip(image=img)[\"image\"]\n","            img = self.aug_v_flip(image=img)[\"image\"]\n","            img = self.aug_distortion(image=img)[\"image\"]\n","            img = self.aug_clahe(image=img)[\"image\"]\n","            img = self.aug_affine(image=img)[\"image\"]\n","            img = self.aug_bright(image=img)[\"image\"]\n","            img = self.aug_cutout(image=img)[\"image\"]\n","            img = self.aug_randomcrop(image=img)[\"image\"]\n","\n","        img = img.astype('float32') / 255\n","        # img.shape: (256, 256)\n","\n","        img = torch.tensor(img, dtype=torch.float).unsqueeze(dim=0)\n","        # img.shape: (1, 256, 256)\n","        if self.model_name == 'maxvit_tiny_tf_384.in1k':\n","            img = Compose([Resize((384, 384), antialias=True)])(img)\n","        img = self.normalize(img)\n","        # img.shape: (1, 256, 256)\n","        if is_on_kaggle and self.model_name == 'maxvit_rmlp_pico_rw_256.sw_in1k':\n","            # convert torch.FloatTensor into torch.cuda.FloatTensor\n","            img = img.cuda()\n","\n","        return {\n","            'image': img, \n","            'patient_id': patient_id,\n","        }\n","    \n","    def _fetch_test_img_paths(self, img_dir):\n","        paths = []\n","        patients_to_series_to_img_paths = defaultdict(lambda: defaultdict(list))\n","        for filename in os.listdir(img_dir):\n","            patient_id, series_id, _ = filename.split('_')\n","            patients_to_series_to_img_paths[patient_id][series_id].append(os.path.join(img_dir, filename))\n","        \n","        for patient_id, series_to_img_paths in patients_to_series_to_img_paths.items():\n","            for series_id, imgs in series_to_img_paths.items():\n","                # sort by instance number\n","                sorted_img_paths = sorted(imgs, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n","                for img_path in sorted_img_paths:\n","                    paths.append(img_path)\n","\n","        return paths\n","\n","    def _process_img(self, img_path):\n","        image = cv2.imread(img_path)\n","        # image = image.astype('float32') / 255\n","        image = (image.astype('float32') * 255).astype('uint8')\n","        greyscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        greyscale = cv2.resize(greyscale, (256, 256))\n","        return greyscale\n","\n","\n","class AbdominalBEDataTest(Dataset):\n","    \n","    def __init__(self, cfg, model_name, test_img_dir, apply_aug=True):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.model_name = model_name\n","        self.augmentation = apply_aug\n","\n","        self.test_img_paths = self._fetch_test_img_paths(test_img_dir)\n","                \n","        self.normalize = Compose([\n","            # Resize((256, 256), antialias=True),\n","            # RandomHorizontalFlip(),  # Randomly flip images left-right\n","            # ColorJitter(brightness=0.2),  # Randomly adjust brightness\n","            # ColorJitter(contrast=0.2),  # Randomly adjust contrast\n","            # RandomAffine(degrees=0, shear=10),  # Apply shear transformation\n","            # RandomAffine(degrees=0, scale=(0.8, 1.2)),  # Apply zoom transformation\n","            # RandomErasing(p=0.2, scale=(0.02, 0.2)),  # Coarse dropout\n","            ToTensor(),\n","        ])\n","\n","        # augmentation\n","        # flip\n","        self.aug_h_flip = A.HorizontalFlip(p=0.5)\n","        self.aug_v_flip = A.VerticalFlip(p=0.5)\n","        # elastic and grid\n","        self.aug_distortion = A.GridDistortion(p=0.5)\n","        self.aug_elastic = A.ElasticTransform(p=0.5)\n","        # affine\n","        self.aug_affine = A.Affine(\n","            scale=(0.8, 1.2),\n","            translate_percent=(0.0, 0.1),\n","            rotate=(-35, 35),\n","            shear=(-15, 15),\n","            p=0.5)\n","        # self.aug_affine = A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.8)\n","        # clahe\n","        self.aug_clahe = A.CLAHE(p=0.5)\n","        # bright\n","        self.aug_bright = A.OneOf([\n","            A.RandomGamma(gamma_limit=(60, 140), p=0.5),\n","            A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.5)\n","        ], p=0.5)\n","        # cutout\n","        self.aug_cutout = A.CoarseDropout(max_height=8, max_width=8, p=0.5)\n","        # randomcrop\n","        self.aug_randomcrop = A.RandomResizedCrop(\n","            height=256,\n","            width=256,\n","            scale=(0.8, 1.0),\n","            ratio=(3/4, 4/3),\n","            p=0.5)\n","    \n","    def __len__(self):\n","        return len(self.test_img_paths)\n","    \n","    def __getitem__(self, idx):\n","        sample_img_path = self.test_img_paths[idx]\n","        patient_id = int(os.path.basename(sample_img_path).split('_')[0])\n","\n","        # preprocess image\n","        img = self._process_img(sample_img_path)\n","        # img.shape: (256, 256)\n","\n","        # augmentation\n","        if self.augmentation:\n","            img = self.aug_h_flip(image=img)[\"image\"]\n","            img = self.aug_v_flip(image=img)[\"image\"]\n","            img = self.aug_distortion(image=img)[\"image\"]\n","            img = self.aug_clahe(image=img)[\"image\"]\n","            img = self.aug_affine(image=img)[\"image\"]\n","            img = self.aug_bright(image=img)[\"image\"]\n","            img = self.aug_cutout(image=img)[\"image\"]\n","            img = self.aug_randomcrop(image=img)[\"image\"]\n","\n","        img = img.astype('float32') / 255\n","        # img.shape: (256, 256)\n","\n","        img = torch.tensor(img, dtype=torch.float).unsqueeze(dim=0)\n","        # img.shape: (1, 256, 256)\n","        if self.model_name == 'maxvit_tiny_tf_384.in1k':\n","            img = Compose([Resize((384, 384), antialias=True)])(img)\n","        img = self.normalize(img)\n","        # img.shape: (1, 256, 256)\n","        if is_on_kaggle and self.model_name == 'maxvit_rmlp_pico_rw_256.sw_in1k':\n","            # convert torch.FloatTensor into torch.cuda.FloatTensor\n","            img = img.cuda()\n","\n","        return {\n","            'image': img, \n","            'patient_id': patient_id,\n","        }\n","    \n","    def _fetch_test_img_paths(self, img_dir):\n","        paths = []\n","        patients_to_series_to_img_paths = defaultdict(lambda: defaultdict(list))\n","        for filename in os.listdir(img_dir):\n","            patient_id, series_id, _ = filename.split('_')\n","            patients_to_series_to_img_paths[patient_id][series_id].append(os.path.join(img_dir, filename))\n","        \n","        for patient_id, series_to_img_paths in patients_to_series_to_img_paths.items():\n","            for series_id, imgs in series_to_img_paths.items():\n","                # sort by instance number\n","                sorted_img_paths = sorted(imgs, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n","                for img_path in sorted_img_paths:\n","                    paths.append(img_path)\n","\n","        return paths\n","\n","    def _process_img(self, img_path):\n","        image = cv2.imread(img_path)\n","        # image = image.astype('float32') / 255\n","        image = (image.astype('float32') * 255).astype('uint8')\n","        greyscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        greyscale = cv2.resize(greyscale, (256, 256))\n","        return greyscale\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:13:42.923029Z","iopub.status.busy":"2023-09-28T08:13:42.922669Z","iopub.status.idle":"2023-09-28T08:13:42.965004Z","shell.execute_reply":"2023-09-28T08:13:42.964040Z","shell.execute_reply.started":"2023-09-28T08:13:42.922996Z"},"trusted":true},"outputs":[],"source":["print('KLS_TEST_DATA_DIR:', KLS_TEST_DATA_DIR)\n","print('B_E_1_TEST_DATA_DIR:', B_E_1_TEST_DATA_DIR)\n","print('B_E_2_TEST_DATA_DIR:', B_E_2_TEST_DATA_DIR)\n","print('apply_aug:', cfg['data']['apply_aug'])\n","kls_test_data = AbdominalKLSDataTest(cfg, cfg['model']['kls_model_name'], KLS_TEST_DATA_DIR, apply_aug=cfg['data']['apply_aug'])\n","b_e_1_test_data = AbdominalBEDataTest(cfg, cfg['model']['b_e_model_name_1'], B_E_1_TEST_DATA_DIR, apply_aug=cfg['data']['apply_aug'])\n","b_e_2_test_data = AbdominalBEDataTest(cfg, cfg['model']['b_e_model_name_2'], B_E_2_TEST_DATA_DIR, apply_aug=cfg['data']['apply_aug'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(kls_test_data), len(b_e_1_test_data), len(b_e_2_test_data)"]},{"cell_type":"markdown","metadata":{},"source":["## Model Architecture ##"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:13:42.770632Z","iopub.status.busy":"2023-09-28T08:13:42.770335Z","iopub.status.idle":"2023-09-28T08:13:42.780183Z","shell.execute_reply":"2023-09-28T08:13:42.779114Z","shell.execute_reply.started":"2023-09-28T08:13:42.770607Z"},"trusted":true},"outputs":[],"source":["# Model Architecure\n","class KLSNet(pl.LightningModule):\n","\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.backbone = timm.create_model(\n","            model_name=cfg['model']['model_name'],\n","            pretrained=cfg['model']['pretrained'],\n","            in_chans=cfg['model']['in_chans'],\n","            num_classes=cfg['model']['num_classes'],\n","            global_pool=cfg['model']['global_pool'],\n","            drop_rate=cfg[\"model\"][\"drop_rate\"],\n","            drop_path_rate=cfg[\"model\"][\"drop_path_rate\"],\n","        )\n","        # for param in self.backbone.parameters():\n","        #     param.requires_grad = False\n","\n","        self.in_features = self.backbone.num_features  # 1280\n","        hidden_dim = cfg['model']['hidden_dim']\n","        self.neck = nn.Sequential(\n","            nn.Linear(self.in_features, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(cfg['model']['p_dropout']),\n","        )\n","\n","        self.kidney = nn.Linear(hidden_dim, 3)\n","        self.liver = nn.Linear(hidden_dim, 3)\n","        self.spleen = nn.Linear(hidden_dim, 3)\n","\n","        self.cce = nn.CrossEntropyLoss(label_smoothing=0.05, weight=torch.tensor(cfg['model']['kls_weights']))\n","\n","        self.train_epoch_loss = []\n","        self.val_epoch_loss = []\n","        self.probs = defaultdict(list)\n","        self.targets = defaultdict(list)\n","        self.auc_scores = dict()\n","\n","    def forward(self, x):\n","        # extract features\n","        x = self.backbone(x)\n","        x = self.neck(x)\n","\n","        # output logits\n","        kidney = self.kidney(x)\n","        liver = self.liver(x)\n","        spleen = self.spleen(x)\n","\n","        return kidney, liver, spleen\n","\n","    def training_step(self, batch, batch_idx):\n","        inputs = batch['image']\n","        kidney = batch['kidney']\n","        liver = batch['liver']\n","        spleen = batch['spleen']\n","\n","        k, l, s = self.forward(inputs)\n","        k_loss = self.cce(k, kidney)\n","        l_loss = self.cce(l, liver)\n","        s_loss = self.cce(s, spleen)\n","        loss = k_loss + l_loss + s_loss\n","        self.train_epoch_loss.append(loss.item())\n","\n","        self.log('train_loss', loss, prog_bar=True, logger=True, on_epoch=True, on_step=True, sync_dist=True)\n","        return loss\n","\n","    # def on_train_epoch_end(self):\n","    #     avg_loss = np.mean(self.train_epoch_loss)\n","    #     self.log('avg_train_loss', avg_loss, prog_bar=True)\n","    #     self.train_epoch_loss.clear()\n","\n","    def validation_step(self, batch, batch_idx):\n","        inputs = batch['image']\n","        kidney = batch['kidney']\n","        liver = batch['liver']\n","        spleen = batch['spleen']\n","\n","        k, l, s = self.forward(inputs)\n","        k_loss = self.cce(k, kidney)\n","        l_loss = self.cce(l, liver)\n","        s_loss = self.cce(s, spleen)\n","        loss = k_loss + l_loss + s_loss\n","        self.val_epoch_loss.append(loss.item())\n","\n","        self.probs['k'].extend(F.softmax(k, dim=1).detach().cpu().numpy())\n","        self.probs['l'].extend(F.softmax(l, dim=1).detach().cpu().numpy())\n","        self.probs['s'].extend(F.softmax(s, dim=1).detach().cpu().numpy())\n","        self.targets['k'].extend(kidney.detach().cpu().numpy())\n","        self.targets['l'].extend(liver.detach().cpu().numpy())\n","        self.targets['s'].extend(spleen.detach().cpu().numpy())\n","\n","        self.log('val_loss', loss, prog_bar=True, logger=True, on_epoch=True, on_step=True, sync_dist=True)\n","        return loss\n","\n","    def on_validation_epoch_end(self):\n","        avg_loss = np.mean(self.val_epoch_loss)\n","\n","        for t in ['k', 'l', 's']:\n","            self.auc_scores[t] = roc_auc_score(\n","                self.targets.get(t),\n","                self.probs.get(t),\n","                multi_class='ovo', labels=[0, 1, 2])\n","\n","        # self.log('avg_val_loss', avg_loss, prog_bar=True)\n","        self.log('val_auc_score_k', self.auc_scores.get('k'), prog_bar=True, sync_dist=True)\n","        self.log('val_auc_score_l', self.auc_scores.get('l'), prog_bar=True, sync_dist=True)\n","        self.log('val_auc_score_s', self.auc_scores.get('s'), prog_bar=True, sync_dist=True)\n","        self.val_epoch_loss.clear()\n","        self.probs.clear()\n","        self.targets.clear()\n","        self.auc_scores.clear()\n","\n","    def configure_optimizers(self):\n","        optimizer = AdamW(self.parameters(), lr=float(self.cfg['model']['lr']))\n","        # optimizer = AdamW(filter(lambda p: p.requires_grad, self.parameters()), lr=float(self.cfg['model']['lr']))\n","        return optimizer\n","\n","    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n","        pass\n","\n","\n","# Model Architecure\n","class BENet(pl.LightningModule):\n","\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","        self.backbone = timm.create_model(\n","            model_name=cfg['model']['model_name'],\n","            pretrained=cfg['model']['pretrained'],\n","            in_chans=cfg['model']['in_chans'],\n","            num_classes=cfg['model']['num_classes'],\n","            global_pool=cfg['model']['global_pool'],\n","            drop_rate=cfg[\"model\"][\"drop_rate\"],\n","            drop_path_rate=cfg[\"model\"][\"drop_path_rate\"],\n","        )\n","        # for param in self.backbone.parameters():\n","        #     param.requires_grad = False\n","\n","        self.in_features = self.backbone.num_features  # 1280\n","        hidden_dim = cfg['model']['hidden_dim']\n","        self.neck = nn.Sequential(\n","            nn.Linear(self.in_features, hidden_dim),\n","            nn.ReLU(),\n","            nn.Dropout(cfg['model']['p_dropout']),\n","        )\n","\n","        self.bowel = nn.Linear(hidden_dim, 2)\n","        self.extravasation = nn.Linear(hidden_dim, 2)\n","\n","        self.cce_b = nn.CrossEntropyLoss(label_smoothing=0.05, weight=torch.tensor(cfg['model']['b_weights']))\n","        self.cce_e = nn.CrossEntropyLoss(label_smoothing=0.05, weight=torch.tensor(cfg['model']['e_weights']))\n","\n","        self.train_epoch_loss = []\n","        self.val_epoch_loss = []\n","        self.probs = defaultdict(list)\n","        self.targets = defaultdict(list)\n","        self.auc_scores = dict()\n","\n","    def forward(self, x):\n","        # extract features\n","        x = self.backbone(x)\n","        x = self.neck(x)\n","\n","        # output logits\n","        bowel = self.bowel(x)\n","        extravsation = self.extravasation(x)\n","\n","        return bowel, extravsation\n","\n","    def training_step(self, batch, batch_idx):\n","        inputs = batch['image']\n","        bowel = batch['bowel']\n","        extravasation = batch['extravasation']\n","\n","        b, e = self.forward(inputs)\n","        b_loss = self.cce_b(b, bowel)\n","        e_loss = self.cce_e(e, extravasation)\n","        loss = b_loss + e_loss\n","        self.train_epoch_loss.append(loss.item())\n","\n","        self.log('train_loss', loss, prog_bar=True, logger=True, on_epoch=True, on_step=True, sync_dist=True)\n","        return loss\n","\n","    # def on_train_epoch_end(self):\n","    #     avg_loss = np.mean(self.train_epoch_loss)\n","    #     self.log('avg_train_loss', avg_loss, prog_bar=True)\n","    #     self.train_epoch_loss.clear()\n","\n","    def validation_step(self, batch, batch_idx):\n","        inputs = batch['image']\n","        bowel = batch['bowel']\n","        extravasation = batch['extravasation']\n","\n","        b, e = self.forward(inputs)\n","        b_loss = self.cce_b(b, bowel)\n","        e_loss = self.cce_e(e, extravasation)\n","        loss = b_loss + e_loss\n","        self.val_epoch_loss.append(loss.item())\n","\n","        self.probs['b'].extend(F.softmax(b, dim=1).detach().cpu().numpy())\n","        self.probs['e'].extend(F.softmax(e, dim=1).detach().cpu().numpy())\n","        self.targets['b'].extend(bowel.detach().cpu().numpy())\n","        self.targets['e'].extend(extravasation.detach().cpu().numpy())\n","\n","        self.log('val_loss', loss, prog_bar=True, logger=True, on_epoch=True, on_step=True, sync_dist=True)\n","        return loss\n","\n","    def on_validation_epoch_end(self):\n","        avg_loss = np.mean(self.val_epoch_loss)\n","\n","        for t in ['b', 'e']:\n","            y_true = np.ravel(self.targets.get(t))\n","            prob_array = np.array(self.probs.get(t))\n","            if len(np.unique(y_true)) != 2:\n","                return -1\n","            self.auc_scores[t] = roc_auc_score(y_true, prob_array[:, 1])\n","\n","        # self.log('avg_val_loss', avg_loss, prog_bar=True)\n","        self.log('val_auc_score_b', self.auc_scores.get('b'), prog_bar=True, sync_dist=True)\n","        self.log('val_auc_score_e', self.auc_scores.get('e'), prog_bar=True, sync_dist=True)\n","        self.val_epoch_loss.clear()\n","        self.probs.clear()\n","        self.targets.clear()\n","        self.auc_scores.clear()\n","\n","    def configure_optimizers(self):\n","        optimizer = AdamW(self.parameters(), lr=float(self.cfg['model']['lr']))\n","        # optimizer = AdamW(filter(lambda p: p.requires_grad, self.parameters()), lr=float(self.cfg['model']['lr']))\n","        return optimizer\n","\n","    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n","        pass\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:13:42.783022Z","iopub.status.busy":"2023-09-28T08:13:42.781691Z","iopub.status.idle":"2023-09-28T08:13:42.893584Z","shell.execute_reply":"2023-09-28T08:13:42.892551Z","shell.execute_reply.started":"2023-09-28T08:13:42.782994Z"},"trusted":true},"outputs":[],"source":["if not is_on_kaggle:\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    kls_model = torch.load(KLS_MODEL_PATH, map_location=device)\n","    b_e_model_1 = torch.load(B_E_MODEL_1_PATH, map_location=device)\n","    b_e_model_2 = torch.load(B_E_MODEL_2_PATH, map_location=device)\n","else:\n","    kls_model = torch.load(KLS_MODEL_PATH)\n","    b_e_model_1 = torch.load(B_E_MODEL_1_PATH)\n","    b_e_model_2 = torch.load(B_E_MODEL_2_PATH)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:13:42.966808Z","iopub.status.busy":"2023-09-28T08:13:42.966242Z","iopub.status.idle":"2023-09-28T08:13:42.972764Z","shell.execute_reply":"2023-09-28T08:13:42.971579Z","shell.execute_reply.started":"2023-09-28T08:13:42.966777Z"},"trusted":true},"outputs":[],"source":["kls_test_dataloader = DataLoader(\n","                    kls_test_data, \n","                    batch_size=cfg['data']['batch_size_inference'], \n","                    shuffle=False, \n","                    num_workers=num_workers, \n","                    pin_memory=True\n","                )\n","\n","b_e_1_test_dataloader = DataLoader(\n","                    b_e_1_test_data, \n","                    batch_size=cfg['data']['batch_size_inference'], \n","                    shuffle=False, \n","                    num_workers=num_workers, \n","                    pin_memory=True\n","                )\n","\n","b_e_2_test_dataloader = DataLoader(\n","                    b_e_2_test_data, \n","                    batch_size=cfg['data']['batch_size_inference'], \n","                    shuffle=False, \n","                    num_workers=num_workers, \n","                    pin_memory=True\n","                )\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Predicting ##"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:13:43.062073Z","iopub.status.busy":"2023-09-28T08:13:43.061720Z","iopub.status.idle":"2023-09-28T08:14:29.157895Z","shell.execute_reply":"2023-09-28T08:14:29.156884Z","shell.execute_reply.started":"2023-09-28T08:13:43.062042Z"},"trusted":true},"outputs":[],"source":["# predict for kls\n","print('batch_size_inference:', cfg['data']['batch_size_inference'])\n","kls_model.eval()\n","kls_test_predictions = []\n","with torch.no_grad():\n","    for batch_idx, batch_data in tqdm(enumerate(kls_test_dataloader)):\n","        image = batch_data['image']\n","        patient_id = batch_data['patient_id']\n","        k, l, s = kls_model(image)\n","        \n","        # Apply activations to get probabilities\n","        k_probs, l_probs, s_probs = map(\n","                lambda x: F.softmax(x, dim=1),\n","                [k, l, s]\n","            )\n","        \n","        # Transfer probabilities back to CPU\n","        k_probs, l_probs, s_probs = map(\n","                lambda x: x.cpu().numpy().astype(np.float64),\n","                [k_probs, l_probs, s_probs]\n","            )\n","\n","        # Get one prediction per series in the batch\n","        for i in range(k_probs.shape[0]):  # Assuming all arrays have the same size\n","            kls_test_predictions.append([\n","                int(patient_id[i]), \n","                *k_probs[i], \n","                *l_probs[i], \n","                *s_probs[i]\n","            ])\n","\n","column_names = ['patient_id', \n","                'kidney_healthy', 'kidney_low', 'kidney_high',\n","                'liver_healthy', 'liver_low', 'liver_high',\n","                'spleen_healthy', 'spleen_low', 'spleen_high']\n","\n","kls_preds = pd.DataFrame(kls_test_predictions, columns=column_names)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:14:29.160206Z","iopub.status.busy":"2023-09-28T08:14:29.159777Z","iopub.status.idle":"2023-09-28T08:14:29.185100Z","shell.execute_reply":"2023-09-28T08:14:29.184110Z","shell.execute_reply.started":"2023-09-28T08:14:29.160167Z"},"trusted":true},"outputs":[],"source":["kls_preds.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:14:29.186801Z","iopub.status.busy":"2023-09-28T08:14:29.186486Z","iopub.status.idle":"2023-09-28T08:14:29.198847Z","shell.execute_reply":"2023-09-28T08:14:29.197719Z","shell.execute_reply.started":"2023-09-28T08:14:29.186770Z"},"trusted":true},"outputs":[],"source":["# aggregate predictions to patient level\n","kls_preds = kls_preds.groupby('patient_id').mean().reset_index()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:14:29.210105Z","iopub.status.busy":"2023-09-28T08:14:29.209011Z","iopub.status.idle":"2023-09-28T08:14:29.226482Z","shell.execute_reply":"2023-09-28T08:14:29.225161Z","shell.execute_reply.started":"2023-09-28T08:14:29.210069Z"},"trusted":true},"outputs":[],"source":["kls_preds.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# predict for b_e 1\n","print('batch_size_inference:', cfg['data']['batch_size_inference'])\n","b_e_model_1.eval()\n","b_e_1_test_predictions = []\n","with torch.no_grad():\n","    for batch_idx, batch_data in tqdm(enumerate(b_e_1_test_dataloader)):\n","        image = batch_data['image']\n","        patient_id = batch_data['patient_id']\n","        b, e = b_e_model_1(image)\n","        \n","        # Apply activations to get probabilities\n","        b_probs, e_probs = map(\n","                lambda x: F.softmax(x, dim=1),\n","                [b, e]\n","            )\n","        \n","        # Transfer probabilities back to CPU\n","        b_probs, e_probs = map(\n","                lambda x: x.cpu().numpy().astype(np.float64),\n","                [b_probs, e_probs]\n","            )\n","\n","        # Get one prediction per series in the batch\n","        for i in range(b_probs.shape[0]):  # Assuming all arrays have the same size\n","            b_e_1_test_predictions.append([\n","                int(patient_id[i]), \n","                *b_probs[i], \n","                *e_probs[i], \n","            ])\n","\n","column_names = ['patient_id', \n","                'bowel_healthy', 'bowel_injury', \n","                'extravasation_healthy', 'extravasation_injury']\n","\n","b_e_1_preds = pd.DataFrame(b_e_1_test_predictions, columns=column_names)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["b_e_1_preds.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# aggregate predictions to patient level\n","b_e_1_preds = b_e_1_preds.groupby('patient_id').mean().reset_index()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["b_e_1_preds.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# predict for b_e 2\n","print('batch_size_inference:', cfg['data']['batch_size_inference'])\n","b_e_model_2.eval()\n","b_e_2_test_predictions = []\n","with torch.no_grad():\n","    for batch_idx, batch_data in tqdm(enumerate(b_e_2_test_dataloader)):\n","        image = batch_data['image']\n","        patient_id = batch_data['patient_id']\n","        b, e = b_e_model_2(image)\n","        \n","        # Apply activations to get probabilities\n","        b_probs, e_probs = map(\n","                lambda x: F.softmax(x, dim=1),\n","                [b, e]\n","            )\n","        \n","        # Transfer probabilities back to CPU\n","        b_probs, e_probs = map(\n","                lambda x: x.cpu().numpy().astype(np.float64),\n","                [b_probs, e_probs]\n","            )\n","\n","        # Get one prediction per series in the batch\n","        for i in range(b_probs.shape[0]):  # Assuming all arrays have the same size\n","            b_e_2_test_predictions.append([\n","                int(patient_id[i]), \n","                *b_probs[i], \n","                *e_probs[i], \n","            ])\n","\n","column_names = ['patient_id', \n","                'bowel_healthy', 'bowel_injury', \n","                'extravasation_healthy', 'extravasation_injury']\n","\n","b_e_2_preds = pd.DataFrame(b_e_2_test_predictions, columns=column_names)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["b_e_2_preds.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# aggregate predictions to patient level\n","b_e_2_preds = b_e_2_preds.groupby('patient_id').mean().reset_index()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["b_e_2_preds.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# take mean\n","b_e_preds = pd.merge(b_e_1_preds, b_e_2_preds, on='patient_id', how='outer', suffixes=('_df1', '_df2'))\n","for column in ['bowel_healthy', 'bowel_injury', 'extravasation_healthy', 'extravasation_injury']:\n","    b_e_preds[column] = b_e_preds[[f\"{column}_df1\", f\"{column}_df2\"]].mean(axis=1)\n","\n","b_e_preds.drop([col for col in b_e_preds.columns if '_df1' in col or '_df2' in col], axis=1, inplace=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# merge\n","df_preds = pd.merge(b_e_preds, kls_preds, on='patient_id', how='outer')\n","# fill na with median of each column\n","columns_to_fill = df_preds.columns.difference(['patient_id'])\n","for column in columns_to_fill:\n","    df_preds[column].fillna(df_preds[column].median(), inplace=True)\n","    \n","# # fill na with mean of each column multiplied by 4 for '*_low' and 'bowel_injury', 6 for '*_high', 28 for extravsation_injury\n","# columns_to_fill = df_preds.columns.difference(['patient_id'])\n","# for column in columns_to_fill:\n","#     if 'low' in column or 'bowel_injury' in column:\n","#         df_preds[column].fillna(df_preds[column].mean() * 4, inplace=True)\n","#     elif 'high' in column:\n","#         df_preds[column].fillna(df_preds[column].mean() * 6, inplace=True)\n","#     elif 'extravasation_injury' in column:\n","#         df_preds[column].fillna(df_preds[column].mean() * 28, inplace=True)\n","#     else:\n","#         df_preds[column].fillna(df_preds[column].mean(), inplace=True)\n","\n","df_preds.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # probability calibration\n","# for column in df_preds.columns.difference(['patient_id']):\n","#     df_preds[column] = df_preds[column].apply(lambda x: 0.0 if x < 0.1 else x)\n","#     df_preds[column] = df_preds[column].apply(lambda x: 1.0 if x > 0.9 else x)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Submission ##"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:14:29.228683Z","iopub.status.busy":"2023-09-28T08:14:29.228074Z","iopub.status.idle":"2023-09-28T08:14:30.369630Z","shell.execute_reply":"2023-09-28T08:14:30.368194Z","shell.execute_reply.started":"2023-09-28T08:14:29.228649Z"},"trusted":true},"outputs":[],"source":["# merge with sample submission\n","if is_on_kaggle:\n","    sample_submission = sample_submission[['patient_id']]\n","    df_preds = pd.merge(sample_submission, df_preds, on='patient_id', how='left')\n","    # fill NaN with median of that column except patient_id \n","    # in case there is no prediction for a patient in df_preds but there is in sample_submission\n","    columns_to_fill = df_preds.columns.difference(['patient_id'])\n","    df_preds[columns_to_fill] = df_preds[columns_to_fill].apply(lambda col: col.fillna(col.median()), axis=0)\n","    # for column in columns_to_fill:\n","    #     if 'low' in column or 'bowel_injury' in column:\n","    #         df_preds[column].fillna(df_preds[column].mean() * 4, inplace=True)\n","    #     elif 'high' in column:\n","    #         df_preds[column].fillna(df_preds[column].mean() * 6, inplace=True)\n","    #     elif 'extravasation_injury' in column:\n","    #         df_preds[column].fillna(df_preds[column].mean() * 28, inplace=True)\n","    #     else:\n","    #         df_preds[column].fillna(df_preds[column].mean(), inplace=True)\n","\n","    # drop duplicates\n","    # df_preds = df_preds.drop_duplicates()\n","    \n","    !rm -rf {KLS_TEST_DATA_DIR}\n","    !rm -rf {B_E_1_TEST_DATA_DIR}\n","    !rm -rf {B_E_2_TEST_DATA_DIR}\n","    print(\"processed for kaggle submission!\")\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:14:30.401887Z","iopub.status.busy":"2023-09-28T08:14:30.401539Z","iopub.status.idle":"2023-09-28T08:14:30.420712Z","shell.execute_reply":"2023-09-28T08:14:30.419714Z","shell.execute_reply.started":"2023-09-28T08:14:30.401862Z"},"trusted":true},"outputs":[],"source":["df_preds.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:14:30.422456Z","iopub.status.busy":"2023-09-28T08:14:30.422030Z","iopub.status.idle":"2023-09-28T08:14:30.444837Z","shell.execute_reply":"2023-09-28T08:14:30.443783Z","shell.execute_reply.started":"2023-09-28T08:14:30.422424Z"},"trusted":true},"outputs":[],"source":["# df_preds.round(3).head()\n","df_preds.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:14:30.452611Z","iopub.status.busy":"2023-09-28T08:14:30.451678Z","iopub.status.idle":"2023-09-28T08:14:30.545864Z","shell.execute_reply":"2023-09-28T08:14:30.544938Z","shell.execute_reply.started":"2023-09-28T08:14:30.452577Z"},"trusted":true},"outputs":[],"source":["# df_preds.to_csv('submission.csv', index=False, float_format='%.2f')\n","# df_preds.round(3).to_csv(\"submission.csv\", index=False)\n","df_preds.to_csv(\"submission.csv\", index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:14:30.547790Z","iopub.status.busy":"2023-09-28T08:14:30.547246Z","iopub.status.idle":"2023-09-28T08:14:30.552564Z","shell.execute_reply":"2023-09-28T08:14:30.551446Z","shell.execute_reply.started":"2023-09-28T08:14:30.547755Z"},"trusted":true},"outputs":[],"source":["# sample_submission = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')\n","# sample_submission.to_csv(\"submission.csv\", index=False)\n","# print(sample_submission.info())\n","# sample_submission.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:14:30.555122Z","iopub.status.busy":"2023-09-28T08:14:30.554321Z","iopub.status.idle":"2023-09-28T08:14:30.562543Z","shell.execute_reply":"2023-09-28T08:14:30.561551Z","shell.execute_reply.started":"2023-09-28T08:14:30.555088Z"},"trusted":true},"outputs":[],"source":["## check to solve scoring error"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:14:30.564772Z","iopub.status.busy":"2023-09-28T08:14:30.564408Z","iopub.status.idle":"2023-09-28T08:14:30.584410Z","shell.execute_reply":"2023-09-28T08:14:30.583178Z","shell.execute_reply.started":"2023-09-28T08:14:30.564739Z"},"trusted":true},"outputs":[],"source":["# # provided by competition organizer\n","# import numpy as np\n","# import pandas as pd\n","# import pandas.api.types\n","# import sklearn.metrics\n","\n","\n","# class ParticipantVisibleError(Exception):\n","#     pass\n","\n","\n","# def normalize_probabilities_to_one(df: pd.DataFrame, group_columns: list) -> pd.DataFrame:\n","#     # Normalize the sum of each row's probabilities to 100%.\n","#     # 0.75, 0.75 => 0.5, 0.5\n","#     # 0.1, 0.1 => 0.5, 0.5\n","#     row_totals = df[group_columns].sum(axis=1)\n","#     if row_totals.min() == 0:\n","#         raise ParticipantVisibleError('All rows must contain at least one non-zero prediction')\n","#     for col in group_columns:\n","#         df[col] /= row_totals\n","#     return df\n","\n","\n","# def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n","#     '''\n","#     Pseudocode:\n","#     1. For every label group (liver, bowel, etc):\n","#         - Normalize the sum of each row's probabilities to 100%.\n","#         - Calculate the sample weighted log loss.\n","#     2. Derive a new any_injury label by taking the max of 1 - p(healthy) for each label group\n","#     3. Calculate the sample weighted log loss for the new label group\n","#     4. Return the average of all of the label group log losses as the final score.\n","#     '''\n","# #     del solution[row_id_column_name]\n","# #     del submission[row_id_column_name]\n","\n","#     # Run basic QC checks on the inputs\n","#     if not pandas.api.types.is_numeric_dtype(submission.values):\n","#         raise ParticipantVisibleError('All submission values must be numeric')\n","\n","#     if not np.isfinite(submission.values).all():\n","#         raise ParticipantVisibleError('All submission values must be finite')\n","\n","#     if solution.min().min() < 0:\n","#         raise ParticipantVisibleError('All labels must be at least zero')\n","#     if submission.min().min() < 0:\n","#         raise ParticipantVisibleError('All predictions must be at least zero')\n","\n","#     # Calculate the label group log losses\n","#     binary_targets = ['bowel', 'extravasation']\n","#     triple_level_targets = ['kidney', 'liver', 'spleen']\n","#     all_target_categories = binary_targets + triple_level_targets\n","\n","#     label_group_losses = []\n","#     for category in all_target_categories:\n","#         if category in binary_targets:\n","#             col_group = [f'{category}_healthy', f'{category}_injury']\n","#         else:\n","#             col_group = [f'{category}_healthy', f'{category}_low', f'{category}_high']\n","\n","#         solution = normalize_probabilities_to_one(solution, col_group)\n","\n","#         for col in col_group:\n","#             if col not in submission.columns:\n","#                 raise ParticipantVisibleError(f'Missing submission column {col}')\n","#         submission = normalize_probabilities_to_one(submission, col_group)\n","#         label_group_losses.append(\n","#             sklearn.metrics.log_loss(\n","#                 y_true=solution[col_group].values,\n","#                 y_pred=submission[col_group].values,\n","#                 sample_weight=solution[f'{category}_weight'].values\n","#             )\n","#         )\n","\n","#     # Derive a new any_injury label by taking the max of 1 - p(healthy) for each label group\n","#     healthy_cols = [x + '_healthy' for x in all_target_categories]\n","#     any_injury_labels = (1 - solution[healthy_cols]).max(axis=1)\n","#     any_injury_predictions = (1 - submission[healthy_cols]).max(axis=1)\n","#     any_injury_loss = sklearn.metrics.log_loss(\n","#         y_true=any_injury_labels.values,\n","#         y_pred=any_injury_predictions.values,\n","#         sample_weight=solution['any_injury_weight'].values\n","#     )\n","\n","#     label_group_losses.append(any_injury_loss)\n","#     return np.mean(label_group_losses)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:14:30.587875Z","iopub.status.busy":"2023-09-28T08:14:30.587051Z","iopub.status.idle":"2023-09-28T08:14:30.614023Z","shell.execute_reply":"2023-09-28T08:14:30.612750Z","shell.execute_reply.started":"2023-09-28T08:14:30.587836Z"},"trusted":true},"outputs":[],"source":["# df_preds.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:14:30.615969Z","iopub.status.busy":"2023-09-28T08:14:30.615656Z","iopub.status.idle":"2023-09-28T08:14:30.632600Z","shell.execute_reply":"2023-09-28T08:14:30.631360Z","shell.execute_reply.started":"2023-09-28T08:14:30.615939Z"},"trusted":true},"outputs":[],"source":["# train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:14:30.634713Z","iopub.status.busy":"2023-09-28T08:14:30.634072Z","iopub.status.idle":"2023-09-28T08:14:30.643866Z","shell.execute_reply":"2023-09-28T08:14:30.642843Z","shell.execute_reply.started":"2023-09-28T08:14:30.634676Z"},"trusted":true},"outputs":[],"source":["# # create solution df from train_df with weight columns\n","# train_df['bowel_weight'] = 1\n","# train_df['extravasation_weight'] = 1\n","# train_df['kidney_weight'] = 1\n","# train_df['liver_weight'] = 1\n","# train_df['spleen_weight'] = 1\n","# train_df['any_injury_weight'] = 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-28T08:14:30.645643Z","iopub.status.busy":"2023-09-28T08:14:30.645261Z","iopub.status.idle":"2023-09-28T08:14:30.718717Z","shell.execute_reply":"2023-09-28T08:14:30.717817Z","shell.execute_reply.started":"2023-09-28T08:14:30.645611Z"},"trusted":true},"outputs":[],"source":["# score(train_df, df_preds, '')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":4}
